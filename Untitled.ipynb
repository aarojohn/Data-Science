{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5591203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib as plt\n",
    "import seaborn as sns \n",
    "%matplotlib notebook\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89c1d36",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7f25c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5935587761674718\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AA       0.41      0.27      0.32     17837\n",
      "          AO       0.41      0.30      0.35     22792\n",
      "          IC       0.67      0.83      0.74     56727\n",
      "          JA       0.37      0.10      0.16      1459\n",
      "          JO       0.25      0.06      0.10       545\n",
      "\n",
      "    accuracy                           0.59     99360\n",
      "   macro avg       0.42      0.31      0.33     99360\n",
      "weighted avg       0.56      0.59      0.56     99360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load your DataFrame\n",
    "# Replace 'my_dataframe.csv' with the path to your CSV file\n",
    "df = pd.read_csv('my_dataframe_ADV.csv')\n",
    "\n",
    "# Define your feature columns and target column\n",
    "# Replace 'target_column' with the name of the column you want to predict\n",
    "target_column = 'Status Code'\n",
    "feature_columns = [col for col in df.columns if col != target_column]\n",
    "\n",
    "# Separate categorical and numeric columns\n",
    "categorical_columns = [col for col in feature_columns if df[col].dtype == 'object']\n",
    "numeric_columns = [col for col in feature_columns if col not in categorical_columns]\n",
    "\n",
    "# Create a preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(# allows you to apply different transformers to different subsets of your columns in a DataFrame\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', numeric_columns),  # numeric columns (no transformation)\n",
    "        ('cat', OneHotEncoder(), categorical_columns)  # one-hot encoding for categorical columns,convert categorical variables into a numerical format\n",
    "    ])\n",
    "\n",
    "# Create and train a Random Forest model within a pipeline\n",
    "rf_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])#The number of decision trees in the Random Forest ensemble is set to 100.\n",
    "# parameter is set to 42 to ensure reproducibility. It initializes the random number generator for consistent results.\n",
    "\n",
    "X = df[feature_columns]\n",
    "y = df[target_column]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# You can evaluate the model's performance using metrics like accuracy, precision, recall, etc.\n",
    "# For example:\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db6579e",
   "metadata": {},
   "source": [
    "# Xgboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08eaccb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6131843800322061\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.29      0.35     17837\n",
      "           1       0.47      0.24      0.32     22792\n",
      "           3       0.66      0.88      0.76     56727\n",
      "           4       0.40      0.06      0.10      1459\n",
      "           5       0.30      0.03      0.05       545\n",
      "\n",
      "    accuracy                           0.61     99360\n",
      "   macro avg       0.46      0.30      0.32     99360\n",
      "weighted avg       0.57      0.61      0.57     99360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load your DataFrame\n",
    "# Replace 'my_dataframe.csv' with the path to your CSV file\n",
    "df = pd.read_csv('my_dataframe_ADV.csv')\n",
    "\n",
    "# Define your feature columns and target column\n",
    "# Replace 'target_column' with the name of the column you want to predict\n",
    "target_column = 'Status Code'\n",
    "feature_columns = [col for col in df.columns if col != target_column]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = df[feature_columns]\n",
    "y = df[target_column]\n",
    "\n",
    "# Check if the target variable is non-numeric\n",
    "if y.dtype == 'object':\n",
    "    # Encode non-numeric class labels to numeric labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Separate categorical and numeric columns\n",
    "categorical_columns = [col for col in X.columns if X[col].dtype == 'object']\n",
    "numeric_columns = [col for col in X.columns if col not in categorical_columns]\n",
    "\n",
    "# Create a preprocessing pipeline to handle categorical and numeric features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', numeric_columns),  # numeric columns (no transformation)\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_columns)  # one-hot encoding for categorical columns\n",
    "    ])\n",
    "\n",
    "# Create and train an XGBoost model within a pipeline\n",
    "xgb_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', xgb.XGBClassifier(n_estimators=100, random_state=42))  # You can adjust hyperparameters\n",
    "])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# If you originally had non-numeric class labels, you can map them back using the label_encoder\n",
    "if y.dtype == 'object':\n",
    "    y_test_original = label_encoder.inverse_transform(y_test)\n",
    "    y_pred_original = label_encoder.inverse_transform(y_pred)\n",
    "else:\n",
    "    y_test_original = y_test\n",
    "    y_pred_original = y_pred\n",
    "\n",
    "# You can evaluate the model's performance using metrics like accuracy, precision, recall, etc.\n",
    "# For example:\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37741492",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd86cd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5272342995169083\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AA       0.29      0.28      0.28     17837\n",
      "          AO       0.35      0.32      0.33     22792\n",
      "          IC       0.66      0.70      0.68     56727\n",
      "          JA       0.22      0.05      0.08      1459\n",
      "          JO       0.19      0.02      0.04       545\n",
      "\n",
      "    accuracy                           0.53     99360\n",
      "   macro avg       0.34      0.28      0.28     99360\n",
      "weighted avg       0.51      0.53      0.52     99360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load your DataFrame\n",
    "# Replace 'my_dataframe.csv' with the path to your CSV file\n",
    "df = pd.read_csv('my_dataframe_ADV.csv')\n",
    "\n",
    "# Define your feature columns and target column\n",
    "# Replace 'target_column' with the name of the column you want to predict\n",
    "target_column = 'Status Code'\n",
    "feature_columns = [col for col in df.columns if col != target_column]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = df[feature_columns]\n",
    "y = df[target_column]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define which columns are categorical and which are numeric\n",
    "categorical_features = [col for col in X.columns if X[col].dtype == 'object']\n",
    "numeric_features = [col for col in X.columns if col not in categorical_features]\n",
    "\n",
    "# Create a preprocessing pipeline to handle categorical and numeric features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', numeric_features),  # numeric columns (no transformation)\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)  # one-hot encoding for categorical columns\n",
    "    ])\n",
    "\n",
    "# Create and train a KNN model within a pipeline\n",
    "knn_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', KNeighborsClassifier(n_neighbors=5))  # You can adjust the number of neighbors and other hyperparameters\n",
    "])\n",
    "\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = knn_model.predict(X_test)\n",
    "\n",
    "# You can evaluate the model's performance using metrics like accuracy, precision, recall, etc.\n",
    "# For example:\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d95f86",
   "metadata": {},
   "source": [
    "# Naive  Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd0e0c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.14091183574879226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\johna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AA       0.24      0.06      0.09     17837\n",
      "          AO       0.28      0.24      0.26     22792\n",
      "          CC       0.00      0.00      0.00         0\n",
      "          IC       0.65      0.12      0.21     56727\n",
      "          JA       0.02      0.19      0.04      1459\n",
      "          JO       0.01      0.45      0.02       545\n",
      "\n",
      "    accuracy                           0.14     99360\n",
      "   macro avg       0.20      0.18      0.10     99360\n",
      "weighted avg       0.48      0.14      0.20     99360\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load your DataFrame\n",
    "# Replace 'my_dataframe.csv' with the path to your CSV file\n",
    "df = pd.read_csv('my_dataframe_ADV.csv')\n",
    "\n",
    "# Define your feature columns and target column\n",
    "# Replace 'target_column' with the name of the column you want to predict\n",
    "target_column = 'Status Code'\n",
    "feature_columns = [col for col in df.columns if col != target_column]\n",
    "\n",
    "# Separate categorical and numeric columns\n",
    "categorical_columns = [col for col in feature_columns if df[col].dtype == 'object']\n",
    "numeric_columns = [col for col in feature_columns if col not in categorical_columns]\n",
    "\n",
    "# Create a preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', numeric_columns),  # numeric columns (no transformation)\n",
    "        ('cat', OneHotEncoder(), categorical_columns)  # one-hot encoding for categorical columns\n",
    "    ])\n",
    "\n",
    "# Create and train a Multinomial Naive Bayes model within a pipeline\n",
    "nb_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', MultinomialNB())\n",
    "])\n",
    "\n",
    "X = df[feature_columns]\n",
    "y = df[target_column]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = nb_model.predict(X_test)\n",
    "\n",
    "# You can evaluate the model's performance using metrics like accuracy, precision, recall, etc.\n",
    "# For example:\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adfb3857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the ensemble: 0.5861111111111111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\johna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AA       0.43      0.20      0.27     17837\n",
      "          AO       0.40      0.35      0.37     22792\n",
      "          CC       0.00      0.00      0.00         0\n",
      "          IC       0.67      0.82      0.74     56727\n",
      "          JA       0.20      0.09      0.13      1459\n",
      "          JO       0.12      0.18      0.15       545\n",
      "\n",
      "    accuracy                           0.59     99360\n",
      "   macro avg       0.30      0.27      0.28     99360\n",
      "weighted avg       0.55      0.59      0.56     99360\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Assuming you have trained models named classifier, KNN, rf_model, and xgb_model\n",
    "\n",
    "# Create a VotingClassifier ensemble\n",
    "ensemble = VotingClassifier(estimators=[\n",
    "    ('nb_model', nb_model),\n",
    "    ('knn_model', knn_model),\n",
    "    ('rf_model', rf_model),\n",
    "    ('xgb_model', xgb_model)\n",
    "], voting='soft')  # 'hard' for classification\n",
    "\n",
    "# Train the ensemble on your training data (X_train, y_train)\n",
    "ensemble.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the ensemble\n",
    "ensemble_predictions = ensemble.predict(X_test)\n",
    "\n",
    "# Evaluate the ensemble's performance\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, ensemble_predictions)\n",
    "print(f'Accuracy of the ensemble: {accuracy}')\n",
    "report = classification_report(y_test, ensemble_predictions)\n",
    "\n",
    "# Print the classification report\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04b917de",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given feature/column names do not match the ones for the data given during fit.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19336/1178063862.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# Use the ensemble to predict the 'Status' for the given feature values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mpredicted_status\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensemble\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Predicted Status: {predicted_status[0]}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_voting.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    307\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvoting\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'soft'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m             \u001b[0mmaj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# 'hard' voting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_voting.py\u001b[0m in \u001b[0;36m_predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    327\u001b[0m         \u001b[1;34m\"\"\"Predict class probabilities for X in 'soft' voting.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 329\u001b[1;33m         avg = np.average(self._collect_probas(X), axis=0,\n\u001b[0m\u001b[0;32m    330\u001b[0m                          weights=self._weights_not_none)\n\u001b[0;32m    331\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mavg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_voting.py\u001b[0m in \u001b[0;36m_collect_probas\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_collect_probas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[1;34m\"\"\"Collect results from clf.predict calls.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_predict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_voting.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_collect_probas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[1;34m\"\"\"Collect results from clf.predict calls.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_predict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    472\u001b[0m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 474\u001b[1;33m             \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    475\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    558\u001b[0m             \u001b[0mX_feature_names\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m                 np.any(self._feature_names_in != X_feature_names)):\n\u001b[1;32m--> 560\u001b[1;33m             raise RuntimeError(\n\u001b[0m\u001b[0;32m    561\u001b[0m                 \u001b[1;34m\"Given feature/column names do not match the ones for the \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m                 \u001b[1;34m\"data given during fit.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given feature/column names do not match the ones for the data given during fit."
     ]
    }
   ],
   "source": [
    "feature_values = {\n",
    "    'TIME OCC': [330],\n",
    "    'AREA': [1],\n",
    "    'Rpt Dist No': [163],\n",
    "    'Crm Cd': [624],\n",
    "    'Vict Age': [25],\n",
    "    'Vict Sex': ['M'],\n",
    "    'Premis Cd': [102],\n",
    "    'Weapon Used Cd': [500]\n",
    "}\n",
    "\n",
    "# Convert the feature values into a DataFrame\n",
    "feature_df = pd.DataFrame(feature_values)\n",
    "\n",
    "# Use the ensemble to predict the 'Status' for the given feature values\n",
    "predicted_status = ensemble.predict(feature_df)\n",
    "\n",
    "print(f'Predicted Status: {predicted_status[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de41038",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b6cc4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
